{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.applications.vgg16 import VGG16\n\n\n# Load and preprocess CIFAR-10 data\n(X_train, y_train), (X_test, y_test) = cifar10.load_data()\nX_train = X_train.astype('float32') / 255.0\nX_test = X_test.astype('float32') / 255.0\n\n# Convert class labels to one-hot encoding\ny_train = to_categorical(y_train, 10)\ny_test = to_categorical(y_test, 10)\n\n# Split training data into training and validation sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\n# Load pre-trained VGG16 without the top layer\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n\n# Add custom classification layers\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.5)(x)\npredictions = Dense(10, activation='softmax')(x)\n\n# Create the complete model\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freeze the base model layers to retain pre-trained weights\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Callbacks for early stopping and learning rate reduction\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n\n# Train the model\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    batch_size=64,\n    epochs=30,\n    callbacks=[early_stopping, lr_scheduler]\n)\n\n# Evaluate the model on the test set\ntest_loss, test_accuracy = model.evaluate(X_test, y_test)\nprint(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n\n# Fine-tune the model by unfreezing some layers of the base model\nfor layer in base_model.layers[-80:]:\n    layer.trainable = True\n\n# Recompile the model with a lower learning rate\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train again with fine-tuning\nfine_tune_history = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    batch_size=64,\n    epochs=30,\n    callbacks=[early_stopping, lr_scheduler]\n)\n\n# Final evaluation\nfinal_loss, final_accuracy = model.evaluate(X_test, y_test)\nprint(f'Final Test Accuracy after Fine-Tuning: {final_accuracy * 100:.2f}%')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-15T00:22:24.077845Z","iopub.execute_input":"2025-01-15T00:22:24.078134Z","iopub.status.idle":"2025-01-15T00:32:23.071651Z","shell.execute_reply.started":"2025-01-15T00:22:24.078111Z","shell.execute_reply":"2025-01-15T00:32:23.070890Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.3825 - loss: 1.7570 - val_accuracy: 0.5479 - val_loss: 1.3060 - learning_rate: 0.0010\nEpoch 2/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5307 - loss: 1.3427 - val_accuracy: 0.5653 - val_loss: 1.2316 - learning_rate: 0.0010\nEpoch 3/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5581 - loss: 1.2704 - val_accuracy: 0.5783 - val_loss: 1.1889 - learning_rate: 0.0010\nEpoch 4/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5688 - loss: 1.2330 - val_accuracy: 0.5855 - val_loss: 1.1719 - learning_rate: 0.0010\nEpoch 5/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5779 - loss: 1.1934 - val_accuracy: 0.5903 - val_loss: 1.1584 - learning_rate: 0.0010\nEpoch 6/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5903 - loss: 1.1717 - val_accuracy: 0.5982 - val_loss: 1.1396 - learning_rate: 0.0010\nEpoch 7/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5945 - loss: 1.1533 - val_accuracy: 0.6034 - val_loss: 1.1317 - learning_rate: 0.0010\nEpoch 8/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6006 - loss: 1.1374 - val_accuracy: 0.6079 - val_loss: 1.1189 - learning_rate: 0.0010\nEpoch 9/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6120 - loss: 1.1136 - val_accuracy: 0.6155 - val_loss: 1.1110 - learning_rate: 0.0010\nEpoch 10/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6128 - loss: 1.0991 - val_accuracy: 0.6122 - val_loss: 1.1022 - learning_rate: 0.0010\nEpoch 11/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6192 - loss: 1.0832 - val_accuracy: 0.6086 - val_loss: 1.1052 - learning_rate: 0.0010\nEpoch 12/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6285 - loss: 1.0692 - val_accuracy: 0.6160 - val_loss: 1.1043 - learning_rate: 0.0010\nEpoch 13/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6252 - loss: 1.0668 - val_accuracy: 0.6142 - val_loss: 1.1065 - learning_rate: 0.0010\nEpoch 14/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6272 - loss: 1.0541 - val_accuracy: 0.6186 - val_loss: 1.0966 - learning_rate: 0.0010\nEpoch 15/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6407 - loss: 1.0336 - val_accuracy: 0.6180 - val_loss: 1.0969 - learning_rate: 0.0010\nEpoch 16/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6359 - loss: 1.0343 - val_accuracy: 0.6234 - val_loss: 1.0920 - learning_rate: 0.0010\nEpoch 17/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6413 - loss: 1.0259 - val_accuracy: 0.6235 - val_loss: 1.0904 - learning_rate: 0.0010\nEpoch 18/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6475 - loss: 1.0085 - val_accuracy: 0.6173 - val_loss: 1.0917 - learning_rate: 0.0010\nEpoch 19/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6507 - loss: 1.0055 - val_accuracy: 0.6206 - val_loss: 1.0921 - learning_rate: 0.0010\nEpoch 20/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6539 - loss: 0.9923 - val_accuracy: 0.6212 - val_loss: 1.0957 - learning_rate: 0.0010\nEpoch 21/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6539 - loss: 0.9848 - val_accuracy: 0.6235 - val_loss: 1.0880 - learning_rate: 0.0010\nEpoch 22/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6561 - loss: 0.9780 - val_accuracy: 0.6192 - val_loss: 1.0940 - learning_rate: 0.0010\nEpoch 23/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6552 - loss: 0.9756 - val_accuracy: 0.6221 - val_loss: 1.0939 - learning_rate: 0.0010\nEpoch 24/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6659 - loss: 0.9567 - val_accuracy: 0.6269 - val_loss: 1.0881 - learning_rate: 0.0010\nEpoch 25/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6610 - loss: 0.9497 - val_accuracy: 0.6310 - val_loss: 1.0848 - learning_rate: 0.0010\nEpoch 26/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6642 - loss: 0.9473 - val_accuracy: 0.6229 - val_loss: 1.0942 - learning_rate: 0.0010\nEpoch 27/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6736 - loss: 0.9393 - val_accuracy: 0.6303 - val_loss: 1.0952 - learning_rate: 0.0010\nEpoch 28/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6705 - loss: 0.9321 - val_accuracy: 0.6248 - val_loss: 1.0949 - learning_rate: 0.0010\nEpoch 29/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6730 - loss: 0.9236 - val_accuracy: 0.6244 - val_loss: 1.0905 - learning_rate: 0.0010\nEpoch 30/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6753 - loss: 0.9169 - val_accuracy: 0.6319 - val_loss: 1.0999 - learning_rate: 0.0010\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6215 - loss: 1.0949\nTest Accuracy: 62.06%\nEpoch 1/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 48ms/step - accuracy: 0.5395 - loss: 1.4481 - val_accuracy: 0.7655 - val_loss: 0.6822 - learning_rate: 1.0000e-04\nEpoch 2/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 46ms/step - accuracy: 0.7841 - loss: 0.6393 - val_accuracy: 0.8046 - val_loss: 0.5724 - learning_rate: 1.0000e-04\nEpoch 3/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 45ms/step - accuracy: 0.8453 - loss: 0.4546 - val_accuracy: 0.8375 - val_loss: 0.5027 - learning_rate: 1.0000e-04\nEpoch 4/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 45ms/step - accuracy: 0.8829 - loss: 0.3452 - val_accuracy: 0.8441 - val_loss: 0.5052 - learning_rate: 1.0000e-04\nEpoch 5/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 45ms/step - accuracy: 0.9145 - loss: 0.2546 - val_accuracy: 0.8413 - val_loss: 0.5273 - learning_rate: 1.0000e-04\nEpoch 6/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 45ms/step - accuracy: 0.9370 - loss: 0.1907 - val_accuracy: 0.8544 - val_loss: 0.5392 - learning_rate: 1.0000e-04\nEpoch 7/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 45ms/step - accuracy: 0.9493 - loss: 0.1521 - val_accuracy: 0.8478 - val_loss: 0.5589 - learning_rate: 1.0000e-04\nEpoch 8/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 45ms/step - accuracy: 0.9647 - loss: 0.1110 - val_accuracy: 0.8387 - val_loss: 0.7120 - learning_rate: 1.0000e-04\nEpoch 9/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 45ms/step - accuracy: 0.9862 - loss: 0.0430 - val_accuracy: 0.8567 - val_loss: 0.7811 - learning_rate: 5.0000e-05\nEpoch 10/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 45ms/step - accuracy: 0.9938 - loss: 0.0210 - val_accuracy: 0.8617 - val_loss: 0.7694 - learning_rate: 5.0000e-05\nEpoch 11/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 45ms/step - accuracy: 0.9903 - loss: 0.0324 - val_accuracy: 0.8562 - val_loss: 0.7823 - learning_rate: 5.0000e-05\nEpoch 12/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 45ms/step - accuracy: 0.9921 - loss: 0.0233 - val_accuracy: 0.8521 - val_loss: 0.8429 - learning_rate: 5.0000e-05\nEpoch 13/30\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.9928 - loss: 0.0244 - val_accuracy: 0.8562 - val_loss: 0.8295 - learning_rate: 5.0000e-05\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8265 - loss: 0.5229\nFinal Test Accuracy after Fine-Tuning: 82.24%\n","output_type":"stream"}],"execution_count":5}]}